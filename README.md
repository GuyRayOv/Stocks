# ğŸ¯ Machine Learning Pipeline Project

This repository contains a complete, modular **machine learning pipeline**, developed using Kaggle's Spotify dataset.  
For more details on the dataset itself, see Kaggle's [documentation](data/README.md.md).


---

## ğŸ“˜ Project Overview

The project implements all major stages of a **supervised machine learning workflow**, including:

1. **Data Preparation** â€“ loading, cleaning, and structuring the raw dataset.  
2. **Exploratory Data Analysis (EDA)** â€“ statistical summaries, visualization, and feature insights.  
3. **Data Cleansing** â€“ outlier detection and imputation of missing values.  
4. **Feature Engineering & Selection** â€“ feature transformation, encoding, and importance ranking.  
5. **Model Selection & Hyperparameter Optimization** â€“ model evaluation and tuning using Grid Search.

Each stage is implemented in a dedicated **Jupyter notebook (.ipynb)** to ensure modularity, clarity, and reproducibility.

---

ğŸ§© Project Structure
```
{REPOSITORY_PATH}/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ README.md                # Kaggle dataset description
â”‚   â””â”€â”€ ProjectPresentation.pptx # Project presentation with visualizations
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1spotify_dataprep.ipynb
â”‚   â”œâ”€â”€ 2spotify_eda.ipynb
â”‚   â”œâ”€â”€ 3spotify_datacleansing.ipynb
â”‚   â”œâ”€â”€ 4spotify_fe.ipynb
â”‚   â””â”€â”€ 5spotify_models.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.json              # Global project configuration file
â”‚   â”œâ”€â”€ my_project_utils.py      # Helper functions (shared across notebooks). For future use, currently empty
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ output/                      # Logs, results, and generated files
â”œâ”€â”€ pickles/                     # Serialized models and data
â”‚
|
â”œâ”€â”€ README.md                    # Project documentation (this file)
â””â”€â”€ .gitignore                   # Ignored files and folders
```

---

## âš™ï¸ Notebook Workflow

Notebooks are **cascading each other** â€” Notebook *N* executes notebook *N-1* first and loads its serialized output (*N-1.pkl*). 
The cascade ends with [notebooks/1spotify_dataprep.ipynb](notebooks/1spotify_dataprep.ipynb), which downloads the Spotify dataset from Kaggle.
Each stage can also be run independently - this behavior is controlled with the `chain_notebooks` flag in [config.json](src/config.json), the project's configuration file that defines all global parameters. 
Including:
- File paths
- Execution order  
- Algorithms for Outlier Detection, Imputation, and Modeling  
- Pipeline control flags (e.g. `split_df` , `chain_notebooks`)

---

## ğŸ§  Data Leakage Prevention

To ensure robust evaluation and prevent data leakage, the Kaggle dataset is split into two independent subsets:

- **Training DataFrame:** `df`  
- **Testing DataFrame:** `df_test`

Both subsets are processed independently throughout the pipeline. This behavior is controlled via the `split_df` flag in `config.json`.

---

## ğŸš€ How to Run

1. **Clone** this repository to your local machine.
2. Open [notebooks/5_spotify_models.ipynb](notebooks/5spotify_models.ipynb) for a full execution, or any notebook for a partial run.
3. Create `.env` file in the root directory of the Runtime, e.g. `/contect/.env`
4. In `.env` define `PROJECT_PATH` to point to your local copy. e.g. `PROJECT_PATH=/content/drive/MyDrive/Projects/GitHub/Spotify/`
5. In `.env` define your Kaggles API params: `KAGGLE_USERNAME=username` and `KAGGLE_API_KEY=apikey`
6. Keep `chain_notebooks : 1` in  [config.json](src/config.json) for an execution of the entire pipline, up to the notebook opend in bullet `2` above
7. Click **Run All**

---

## ğŸ“Š Project Deliverables

- **Jupyter Notebooks**. One per ML pipeline stage under [notebooks/](notebooks/)  
- **Configuration File**. A centralized global parameters file [config.json](src/config.json)  
- **Presentation Deck**. Key insights and visualizations [data/ProjectPresentation.pptx](data/ProjectPresentation.pptx)

---
