{"cells":[{"cell_type":"markdown","metadata":{"id":"4Ns2SNtAqGwM"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hjNT5fdaAq2u"},"outputs":[],"source":["import sys\n","import os\n","from google.colab import drive\n","from google.colab import files\n","from dotenv import load_dotenv\n","import json\n","import warnings\n","import pickle\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","warnings.filterwarnings(\"ignore\")\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"DRGyC6FrqbZA"},"source":["# Bootstrap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gch0QCmZIG5C"},"outputs":[],"source":["np.random.seed(31071967)\n","\n","# Find and load the .env file from the current or parent directories\n","load_dotenv()\n","\n","drive.mount('/content/drive')\n","\n","with open(f\"{os.getenv('PROJECT_PATH')}/src/config.json\", 'r') as f:\n","    project_config = json.load(f)\n","    project_config.pop('_comment', None)\n","    project_config.pop('_note', None)\n","    project_config.pop\n","    f.close()"]},{"cell_type":"code","source":["project_config['STOCKS'] = project_config['STOCKS'].split()\n","project_config['TKL'] = project_config['STOCKS'][0]"],"metadata":{"id":"ZM6NNI3gGtMW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YY6gc_3UZbUo"},"outputs":[],"source":["if project_config['chain_notebooks'] == '1':\n","\n","  !pip install papermill\n","  !pip install nbconvert\n","  !pip install nbformat\n","  !pip install IPython\n","\n","  import papermill as pm\n","  import nbformat\n","  from nbconvert import HTMLExporter\n","  from IPython.display import HTML, display\n","\n","  input_file = f\"{os.getenv('PROJECT_PATH')}{project_config['notebooks_directory']}{project_config['notebook1']}\"\n","  output_file = f\"{os.getenv('PROJECT_PATH')}{project_config['output_directory']}{project_config['output1']}\"\n","\n","  # --- Execute the proviuse notebook with parameters ---\n","  pm.execute_notebook(\n","      input_path = input_file,\n","      output_path = output_file,\n","      log_output=False,  # don't print logs while running\n","      progress_bar=True\n","  )\n","\n","  # --- Convert the executed notebook to HTML ---\n","  nb = nbformat.read(output_file, as_version=4)\n","  html_exporter = HTMLExporter()\n","  html_exporter.template_name = \"lab\"  # modern look; alternatives: 'classic', 'basic'\n","  body, _ = html_exporter.from_notebook_node(nb)\n","\n","  # --- Display the HTML result inline ---\n","  display(HTML(body))"]},{"cell_type":"code","source":["tickers_yf = {\n","    \"y\"     : f\"{project_config['TKL']}\",\n","    \"NASDAQ\"       : \"^IXIC\",\n","    \"SP500\"        : \"^GSPC\",\n","    \"Gold\"         : \"GC=F\",\n","    \"Oil\"          : \"CL=F\",\n","    \"RealEstate\"   : \"VNQ\",\n","    \"InflationExp\": \"^TNX\"\n","}\n","\n","desired_order = [\n","    \"Date\",\n","    \"y\",\n","    \"NASDAQ\",\n","    \"SP500\",\n","    \"Oil\",\n","    \"Gold\",\n","    \"RealEstate\",\n","    \"InflationExp\",\n","]"],"metadata":{"id":"7LUL6NLy72f5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import yfinance as yf\n","import pandas as pd\n","from pandas_datareader import data as pdr\n","\n","from datetime import date, timedelta\n","end_date = date.today() - timedelta(days=1)\n","start_date = end_date - timedelta(days=int(project_config[\"HISTORY_DEPTH\"]))\n","\n","if project_config['TKL'] == 'TNYA':\n","  start_date = pd.to_datetime(\"31.07.2022\", format=\"%d.%m.%Y\")\n","\n","# ---- DOWNLOAD FROM YAHOO FINANCE ----\n","ts_yf = yf.download(\n","    tickers=list(tickers_yf.values()),\n","    start=start_date,\n","    end=end_date,\n","    auto_adjust=True\n",")[\"Close\"]\n","\n","# rename columns to readable names\n","rename_map = {v: k for k, v in tickers_yf.items()}\n","ts_yf = ts_yf.rename(columns=rename_map)\n","\n","# Fill missing daily values for macro data (monthly)\n","ts_yf = ts_yf.fillna(method='ffill').fillna(method='bfill')\n","ts_yf = ts_yf.reset_index().rename(columns={\"Date\": \"Date\",})\n","\n","print(f\"\\n\\nDataset for y={project_config['TKL']}\")\n","display(ts_yf.head(1))\n","display(ts_yf.tail(1))\n","ts_yf.info()"],"metadata":{"id":"CcGxZwc479c0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = ts_yf.copy()\n","df_orig = ts_yf.copy()\n","\n","# Keep Date\n","date_col = df[\"Date\"]\n","\n","# Targets\n","y_col = ['y']\n","\n","# Features\n","X_cols = df.drop(columns=y_col+['Date']).columns\n","\n","# Initialize scalers\n","from sklearn.preprocessing import MinMaxScaler\n","X_scaler = MinMaxScaler()\n","y_scaler = MinMaxScaler()\n","\n","# Scale\n","df_X_scaled = pd.DataFrame(X_scaler.fit_transform(df[X_cols]),\n","                           columns=X_cols, index=df.index)\n","\n","df_y_scaled = pd.DataFrame(y_scaler.fit_transform(df[y_col]),\n","                           columns=y_col, index=df.index)\n","\n","# Rebuild dataframe\n","df = pd.concat([date_col, df_X_scaled, df_y_scaled], axis=1)\n","\n","df = df[desired_order]\n","df_orig = df_orig[desired_order]\n","\n","del df_X_scaled, df_y_scaled\n","\n","display(df.tail(1))\n","display(df_orig.tail(1))"],"metadata":{"id":"KFYxPL8b8A_s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_ts_features(df, lags=[2,3,4,5,6,10,22,66], windows=[5,10,22,66]):\n","\n","  # Identify columns to generate features for (excluding 'index' column which is the date)\n","  base_cols = [c for c in df.columns if c not in ['Date','index']]\n","\n","  for base_col in base_cols:\n","\n","    for lag in lags:\n","      df[f\"{base_col}_lag_{lag}\"] = df[base_col].shift(lag)\n","\n","  # Generate rolling window statistics for the current base_col\n","    for window in windows:\n","      df[f\"{base_col}_min_{window}\"] = df[base_col].rolling(window=window).min()\n","      df[f\"{base_col}_max_{window}\"] = df[base_col].rolling(window=window).max()\n","      df[f\"{base_col}_mean_{window}\"] = df[base_col].rolling(window=window).mean()\n","      df[f\"{base_col}_std_{window}\"]  = df[base_col].rolling(window=window).std()\n","      df[f\"{base_col}_diff_{window}\"] = df[base_col].diff(window)\n","      df[f\"{base_col}_pct_{window}\"] = df[base_col].pct_change(window)\n","\n","  df['y_next'] = df['y'].shift(-1)                            # y_next = tomorrow's y (close price)\n","  df.loc[df.index[-1], 'y_next'] = df.loc[df.index[-1], 'y']  # the TARGET cell. y_next tomorrow = y today\n","  df = df.fillna(method='ffill').fillna(method='bfill')\n","\n","  return df\n","\n","df = generate_ts_features(df)\n","df_orig = generate_ts_features(df_orig)\n","\n","# Replace infinite values with NaN in X_train and y_train\n","df = df.replace([np.inf, -np.inf], np.nan)\n","df = df.fillna(method='ffill').fillna(method='bfill')\n","\n","display(df.tail(1))\n","display(df_orig.tail(1))"],"metadata":{"id":"U5zy5Pbx8D4n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df.drop(columns=['Date','y_next'])\n","y = df['y_next']\n","\n","X_train, X_test = X.iloc[:-2], X.iloc[-1:]\n","y_train, y_test = y.iloc[:-2], y.iloc[-1:]\n","\n","del X,y\n","\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"],"metadata":{"id":"sg5V2yZd8JSz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from xgboost import XGBRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","xgb = XGBRegressor(\n","    n_estimators=300,\n","    max_depth=5,\n","    learning_rate=0.05,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    objective=\"reg:squarederror\")\n","\n","xgb.fit(X_train, y_train)"],"metadata":{"id":"e7RltrgL8RKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred = xgb.predict(X_test)\n","pred_orig = y_scaler.inverse_transform(pred.reshape(-1, 1))[0, 0] # Corrected to use NumPy indexing\n","\n","df.loc[df.index[-1], 'y_next'] = pred\n","df_orig.loc[df_orig.index[-1], 'y_next'] = pred_orig\n","\n","print(f\"{project_config['TKL']} {df['Date'].iloc[-1].date()} ${pred_orig:.2f}\")\n","display(df.tail(1))\n","display(df_orig.tail(1))"],"metadata":{"id":"4OFKSP7x8VEp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import xgboost # Import the xgboost module\n","\n","# Plot feature importance based on \"weight\" (number of times a feature appears in a tree)\n","plt.figure(figsize=(10, 6))\n","xgboost.plot_importance(xgb, max_num_features=20) # Pass the xgb regressor object\n","plt.title(\"Feature Importance (Weight)\")\n","plt.show()\n","\n","# 1. Get feature importance by weight\n","importance_dict = xgb.get_booster().get_score(importance_type='weight')\n","\n","# 2. Convert to DataFrame\n","df_importance = pd.DataFrame(list(importance_dict.items()), columns=['Feature', 'Score'])\n","\n","# 3. Sort high → low\n","df_importance = df_importance.sort_values(by='Score', ascending=False)\n","\n","# 4. Compute threshold = 10% of top feature\n","top_score = df_importance['Score'].iloc[0]\n","threshold = top_score * 0.05   # 5%\n","\n","# 5. Select only strong features\n","df_top = df_importance[df_importance['Score'] >= threshold]\n","\n","# 6. Convert to list\n","top_weight_features_list = df_top['Feature'].tolist()[:10:]\n","\n","print(\"Weight Threshold:\", threshold)\n","print(\"Selected Weight Features:\", top_weight_features_list)"],"metadata":{"id":"lMGY5V5c8cbs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# OPTIONAL: Plot based on \"gain\" (average gain of splits which use the feature)\n","# \"Gain\" is often more accurate for finding what actually drives the prediction.\n","plt.figure(figsize=(10, 6))\n","xgboost.plot_importance(xgb, importance_type='gain', max_num_features=20) # Pass the xgb regressor object\n","plt.title(\"Feature Importance (Gain)\")\n","plt.show()\n","\n","# 1. Build importance DataFrame\n","importance_dict = xgb.get_booster().get_score(importance_type='gain')\n","df_importance = pd.DataFrame(list(importance_dict.items()), columns=['Feature', 'Score'])\n","\n","# 2. Sort high to low\n","df_importance = df_importance.sort_values(by='Score', ascending=False)\n","\n","# 3. Compute threshold = 10% of top feature\n","top_score = df_importance['Score'].iloc[0]\n","threshold = top_score * 0.05\n","\n","# 4. Select features with Score >= threshold\n","df_top = df_importance[df_importance['Score'] >= threshold]\n","\n","# 5. Extract feature names\n","top_gain_features_list = df_top['Feature'].tolist()[:10:]\n","\n","print(\"Threshold:\", threshold)\n","print(\"Selected features:\", top_gain_features_list)"],"metadata":{"id":"_moMneSf8ea2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_features = list(set(top_gain_features_list) | set(top_weight_features_list))\n","top_features"],"metadata":{"id":"Skemoxht8gml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_df = df[['Date','y_next'] + top_features]\n","\n","for col in top_features + ['y_next']:\n","  final_df[f\"{col}_orig\"] = df_orig[col]\n","\n","display(final_df.tail(1))\n","final_df.info()"],"metadata":{"id":"S1FVpS5W8jNI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_csv_path = f\"{os.getenv('PROJECT_PATH')}{project_config['data_directory']}{project_config['TKL']}.df.csv\"\n","final_df[:-1:].to_csv(df_csv_path)"],"metadata":{"id":"MGIxwWx38lEJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6X7iNBA80O3"},"source":["# Load dataset file of current TKL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZNVRwh78gCz"},"outputs":[],"source":["print(f\"Loading dataset for {project_config['TKL']} .....\\n\")\n","\n","DATASET = f\"{os.getenv('PROJECT_PATH')}{project_config['data_directory']}{project_config['TKL']}.df.csv\"\n","df_all = pd.read_csv(DATASET, index_col=False)\n","df_all = df_all.drop(columns=[\"Unnamed: 0\"])\n","\n","cols_orig = [col for col in df_all.columns if col.endswith('_orig')]\n","cols_normalized = [col for col in df_all.columns if not col.endswith('_orig')]\n","\n","df = df_all[cols_normalized]\n","df_orig = df_all[['Date'] + cols_orig]\n","\n","print(f\"\\ndf for training\")\n","print(f\"-----------------\")\n","display(df.tail(1))\n","\n","print(f\"\\ndf for visualization\")\n","print(f\"----------------------\")\n","display(df_orig.tail(1))"]},{"cell_type":"markdown","metadata":{"id":"zcp4t8WgCz-0"},"source":["# Data prep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MGNujJS1EEvV"},"outputs":[],"source":["def make_datasets(df, X_cols, y_col):\n","\n","    LOOK_BACK_DAYS = int(project_config['LOOK_BACK_DAYS'])\n","\n","    X, y = [], []\n","\n","    for i in range(LOOK_BACK_DAYS, len(df)):\n","        X.append(df.loc[i-LOOK_BACK_DAYS:i-1, X_cols].values)\n","        y.append(df.loc[i, y_col].values[0])\n","\n","    X = np.array(X, dtype=np.float32)\n","    y = np.array(y, dtype=np.float32)\n","    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n","\n","    split = int(0.8 * len(X))\n","    X_train, X_test = X[:split], X[split:]\n","    y_train, y_test = y[:split], y[split:]\n","\n","    dates = pd.to_datetime(df['Date'])\n","    dates_test = dates[-len(y_test):].values\n","\n","    return X_train, X_test, y_train, y_test, dates_test"]},{"cell_type":"markdown","source":["# Train Predict"],"metadata":{"id":"UHhclNMBITSZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANWmCT8mGhci"},"outputs":[],"source":["def train_predict(X_train, X_test, y_train, y_test, features, model_name, epochs=0, batch_size=0):\n","\n","  from tensorflow.keras.models import Sequential, Model\n","  from tensorflow.keras.layers import LSTM, Dense, GRU, Conv1D, MaxPooling1D, Flatten, Dropout, Input, Concatenate\n","\n","  epochs = int(project_config['TRAIN_EPOCS']) if epochs == 0 else epochs\n","  batch_size = int(project_config['TRAIN_BATCH_SIZE']) if batch_size == 0 else batch_size\n","\n","  if model_name == 'Parallel.LSTM.GRU':\n","    input_layer = Input(shape=(X_train.shape[1],X_train.shape[2]))\n","    lstm_branch = LSTM(units=50, return_sequences=False)(input_layer)\n","    gru_branch = GRU(units=50, return_sequences=False)(input_layer)\n","    merged = Concatenate()([lstm_branch, gru_branch])\n","    dropout = Dropout(0.1, name='dropout_layer')(merged)\n","    output_layer = Dense(1, activation='sigmoid')(dropout)\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","\n","  if model_name == 'Cascase.CNN.GRU':\n","    model = Sequential([\n","        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])),\n","        MaxPooling1D(pool_size=2),\n","        GRU(50, return_sequences=False),\n","        Dense(25, activation='relu'),\n","        Dense(1)\n","  ])\n","\n","  if model_name == 'Cascase.CNN.LSTM':\n","    model = Sequential([\n","        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])),\n","        MaxPooling1D(pool_size=2),\n","        LSTM(50, return_sequences=False),\n","        Dense(25, activation='relu'),\n","        Dense(1)\n","  ])\n","\n","  if model_name == 'CNN':\n","    model = Sequential([\n","        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])),\n","        MaxPooling1D(pool_size=2),\n","        Conv1D(filters=128, kernel_size=3, activation='relu'),\n","        MaxPooling1D(pool_size=2),\n","        Flatten(),\n","        Dense(100, activation='relu'),\n","        Dropout(0.2),\n","        Dense(1)\n","  ])\n","\n","  if model_name == 'LSTM':\n","    model = Sequential([\n","        LSTM(50, return_sequences=True, input_shape=(X_train.shape[1],X_train.shape[2])),\n","        LSTM(10),\n","        Dense(1)\n","  ])\n","\n","  if model_name == 'GRU':\n","    model = Sequential([\n","      GRU(50, return_sequences=True, input_shape=(X_train.shape[1],X_train.shape[2])),\n","      GRU(10),\n","      Dense(1)\n","  ])\n","\n","  model.compile(optimizer='adam', loss='mse')\n","\n","  print(\"\\n=====================================================================\\n\")\n","  print(f\"TKL: {project_config['TKL']}\")\n","  print(f\"Model: {model_name}\")\n","  print(f\"Features: {features}\")\n","  model.summary()\n","\n","  history = model.fit(X_train, y_train,\n","                      epochs=int(project_config['TRAIN_EPOCS']),\n","                      batch_size=int(project_config['TRAIN_BATCH_SIZE']),\n","                      validation_data=(X_test, y_test),\n","                      verbose=1)\n","\n","  pred = model.predict(X_test)\n","  unscaled_prediction = y_scaler.inverse_transform(pred.reshape(-1, 1))\n","  unscaled_y_test = y_scaler.inverse_transform(y_test.reshape(-1, 1))\n","\n","  from sklearn.metrics import mean_absolute_error\n","  mae = mean_absolute_error(unscaled_y_test, unscaled_prediction)\n","\n","  from sklearn.metrics import r2_score\n","  r2 = r2_score(unscaled_y_test, unscaled_prediction)\n","\n","  print(f\"TKL: {project_config['TKL']}\")\n","  print(f\"Model: {model_name}\")\n","  print(f\"Features: {features}\")\n","  print(f\"MAE: {mae:.4f}\")\n","  print(f\"R²: {r2:.4f}\")\n","\n","  return unscaled_prediction, unscaled_y_test, model"]},{"cell_type":"markdown","source":["# Racing Models"],"metadata":{"id":"cihXcKfHILkK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2cGh7McfuF7p"},"outputs":[],"source":["X_cols_full = [col for col in df.columns if col not in ['Date','y_next']]\n","X_cols_exho = [col for col in df.columns if '_' not in col and col != 'Date']\n","X_cols_tkl  = ['y']\n","y_col       = ['y_next']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwaRKpLaPW-Y"},"outputs":[],"source":["from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import r2_score\n","\n","def race_models(tkl, models_to_try):\n","\n","  results_df = pd.DataFrame(columns=[ \"model_name\", \"X_cols\",  \"prediction\", \"mae\", \"r2\", \"model\" ])\n","\n","  for X_cols in [X_cols_full, X_cols_exho, X_cols_tkl]:\n","\n","    X_train, X_test, y_train, y_test, dates_test = make_datasets(df, X_cols, y_col)\n","\n","    if 'Parallel.LSTM.GRU' in models_to_try:\n","      unscaled_prediction, unscaled_y_test, model = train_predict(X_train, X_test, y_train, y_test, X_cols, model_name=\"Parallel.LSTM.GRU\")\n","      results_df.loc[len(results_df)] = {\n","        \"model_name\": \"Parallel.LSTM.GRU\",\n","        \"X_cols\": X_cols,\n","        \"prediction\": unscaled_prediction,\n","        \"mae\": mean_absolute_error(unscaled_y_test, unscaled_prediction),\n","        \"r2\": r2_score(unscaled_y_test, unscaled_prediction),\n","        \"model\": model\n","        }\n","\n","    if 'Cascase.CNN.GRU' in models_to_try:\n","      unscaled_prediction, unscaled_y_test, model = train_predict(X_train, X_test, y_train, y_test, X_cols, model_name=\"Cascase.CNN.GRU\")\n","      results_df.loc[len(results_df)] = {\n","        \"model_name\": \"Cascase.CNN.GRU\",\n","        \"X_cols\": X_cols,\n","        \"prediction\": unscaled_prediction,\n","        \"mae\": mean_absolute_error(unscaled_y_test, unscaled_prediction),\n","        \"r2\": r2_score(unscaled_y_test, unscaled_prediction),\n","        \"model\": model\n","        }\n","\n","    if 'Cascase.CNN.LSTM' in models_to_try:\n","      unscaled_prediction, unscaled_y_test, model = train_predict(X_train, X_test, y_train, y_test, X_cols, model_name=\"Cascase.CNN.LSTM\")\n","      results_df.loc[len(results_df)] = {\n","        \"model_name\": \"Cascase.CNN.LSTM\",\n","        \"X_cols\": X_cols,\n","        \"prediction\": unscaled_prediction,\n","        \"mae\": mean_absolute_error(unscaled_y_test, unscaled_prediction),\n","        \"r2\": r2_score(unscaled_y_test, unscaled_prediction),\n","        \"model\": model\n","        }\n","\n","    if 'CNN' in models_to_try:\n","      unscaled_prediction, unscaled_y_test, model = train_predict(X_train, X_test, y_train, y_test, X_cols, model_name=\"CNN\")\n","      results_df.loc[len(results_df)] = {\n","        \"model_name\": \"CNN\",\n","        \"X_cols\": X_cols,\n","        \"prediction\": unscaled_prediction,\n","        \"mae\": mean_absolute_error(unscaled_y_test, unscaled_prediction),\n","        \"r2\": r2_score(unscaled_y_test, unscaled_prediction),\n","        \"model\": model\n","        }\n","\n","    if 'GRU' in models_to_try:\n","      unscaled_prediction, unscaled_y_test, model = train_predict(X_train, X_test, y_train, y_test, X_cols, model_name=\"GRU\")\n","      results_df.loc[len(results_df)] = {\n","        \"model_name\": \"GRU\",\n","        \"X_cols\": X_cols,\n","        \"prediction\": unscaled_prediction,\n","        \"mae\": mean_absolute_error(unscaled_y_test, unscaled_prediction),\n","        \"r2\": r2_score(unscaled_y_test, unscaled_prediction),\n","        \"model\": model\n","      }\n","\n","    if 'LSTM' in models_to_try:\n","      unscaled_prediction, unscaled_y_test, model = train_predict(X_train, X_test, y_train, y_test, X_cols, model_name=\"LSTM\")\n","      results_df.loc[len(results_df)] = {\n","        \"model_name\": \"LSTM\",\n","        \"X_cols\": X_cols,\n","        \"prediction\": unscaled_prediction,\n","        \"mae\": mean_absolute_error(unscaled_y_test, unscaled_prediction),\n","        \"r2\": r2_score(unscaled_y_test, unscaled_prediction),\n","        \"model\": model\n","      }\n","\n","  return results_df, dates_test, unscaled_y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCf0K2YbX2yl"},"outputs":[],"source":["def plot_results(results_df, dates_test, unscaled_y_test):\n","\n","  import matplotlib.dates as mdates # Added import\n","\n","  for model_name in results_df.model_name.unique():\n","    plt.figure(figsize=(10,6))\n","    plt.title(f\"{project_config['TKL']} {model_name}\")\n","    # Note: unscaled_y_test and dates_test are assumed to be defined in the global scope\n","    # and represent the test data for comparison with all predictions.\n","    plt.plot(dates_test, unscaled_y_test, label=f\"Actual\", linewidth=2, color='black')\n","\n","    # Corrected iteration: iterate over rows using .iterrows()\n","    for index, entry in results_df[results_df.model_name == model_name].iterrows():\n","      plt.plot(dates_test, entry.prediction, label=f\"features: {entry.X_cols}\", linestyle='--')\n","\n","    ax = plt.gca()\n","    ax.xaxis.set_major_locator(mdates.MonthLocator())\n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n","\n","    plt.xticks(rotation=45)\n","    plt.tight_layout()\n","\n","    plt.legend()\n","    plt.show()\n","\n","  # Convert lists in 'X_cols' to tuples for unique identification\n","  # This is necessary because lists are unhashable, causing TypeError with .unique()\n","  results_df['X_cols_tuple'] = results_df['X_cols'].apply(tuple)\n","\n","  for features_tuple in results_df.X_cols_tuple.unique():\n","    plt.figure(figsize=(10,6))\n","    # Convert tuple back to list for display purposes in the title\n","    features = list(features_tuple)\n","    plt.title(f\"{project_config['TKL']} {features}\")\n","    # Note: unscaled_y_test and dates_test are assumed to be defined in the global scope\n","    # and represent the test data for comparison with all predictions.\n","    plt.plot(dates_test, unscaled_y_test, label=f\"Actual\", linewidth=2, color='black')\n","\n","    # Corrected iteration: iterate over rows using .iterrows()\n","    for index, entry in results_df[results_df.X_cols_tuple == features_tuple].iterrows():\n","      plt.plot(dates_test, entry.prediction, label=f\":{entry.model_name}\", linestyle='--')\n","\n","    ax = plt.gca()\n","    ax.xaxis.set_major_locator(mdates.MonthLocator())\n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n","\n","    plt.xticks(rotation=45)\n","    plt.tight_layout()\n","\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","source":["# def predict_next_days(winning_model, winning_model_name, winning_model_features, future_days=10):\n","\n","#   # Re-create X_train, X_test, y_train, y_test, dates_test with the winning model's features\n","#   # This ensures that X_test has the correct number of features for the winning_model.\n","#   X_train_winning, X_test_winning, y_train_winning, y_test_winning, dates_test_winning = make_datasets(df, winning_model_features, y_col)\n","\n","#   last_historical_block = X_test_winning[-1:] # Select the last sequence from X_test_winning\n","#   last_historical_day = df.iloc[-1].Date\n","#   future_rolling_block = last_historical_block.copy()\n","#   future_predictions = []\n","\n","#   for _ in range(future_days):\n","\n","#     next_pred_day = winning_model.predict(future_rolling_block)[0]\n","#     future_predictions.append(next_pred_day)\n","#     # To simulate new data, shift the window and replace the last element with the new prediction\n","#     # The new prediction (next_pred_day) represents 'y_next', so it becomes the 'y' feature\n","#     # in the next time step's input block. Other features would need to be synthesized or assumed.\n","#     # For simplicity and given the model was trained on ['y', 'NASDAQ'] with 'y_next' as target,\n","#     # we need to ensure the rolling block maintains the correct feature structure.\n","#     # The error suggests a feature mismatch, so for a simple 'y' and 'NASDAQ' model,\n","#     # we need to ensure 'future_rolling_block' is updated correctly.\n","\n","#     # The original implementation `future_rolling_block[:, -1, 0] = next_pred_day`\n","#     # implicitly assumes a single feature is being updated, which is correct for\n","#     # a model trained on only ['y']. For a model trained on ['y', 'NASDAQ'],\n","#     # if 'y' is the first feature (index 0) and 'NASDAQ' is the second (index 1),\n","#     # we can update the 'y' feature and either leave 'NASDAQ' as is or synthesize it.\n","#     # Given the problem's focus on `y_next`, it is reasonable to assume that the 'y' feature\n","#     # in the input sequence is what `next_pred_day` is meant to update.\n","\n","#     # Let's adjust `future_rolling_block` to correctly handle multiple features if the winning model requires it.\n","#     # If the winning model uses multiple features, the prediction `next_pred_day` (which is 'y_next')\n","#     # corresponds to the 'y' feature for the next time step. The other features ('NASDAQ' in this case)\n","#     # would typically need to be forecasted or carried forward.\n","#     # For this simple rolling prediction, we'll assume the predicted 'y' replaces the 'y' feature\n","#     # in the next input window, and other features remain the same from the last historical block\n","#     # or are also predicted/synthesized.\n","\n","#     # For a model with ['y', 'NASDAQ'] features, if the input is (batch, timesteps, features):\n","#     # future_rolling_block should have shape (1, LOOK_BACK_DAYS, num_features).\n","#     # next_pred_day is a single value, representing the predicted 'y_next'.\n","#     # We need to update the 'y' feature in the new time step of the rolling block.\n","#     # Assuming 'y' is the first feature (index 0) and NASDAQ is the second (index 1).\n","#     # The `np.roll` operation shifts the time series data. We then update the last time step's features.\n","\n","#     # Create a new row for the next time step, assuming 'y' is the first feature.\n","#     # If 'winning_model_features' was more complex and included 'NASDAQ',\n","#     # we would need a way to populate the 'NASDAQ' value for the next step.\n","#     # For now, let's assume `next_pred_day` updates the *first* feature (index 0) in the last time step\n","#     # of the rolling window, and if other features exist, they remain as they were in the previous last time step.\n","\n","#     new_input_row = future_rolling_block[0, -1, :].copy() # Copy last row of features\n","#     new_input_row[0] = next_pred_day # Update the 'y' feature (first feature)\n","\n","#     future_rolling_block = np.roll(future_rolling_block, -1, axis=1) # Shift time window\n","#     future_rolling_block[0, -1, :] = new_input_row # Place the new feature vector at the end\n","\n","#   # Calculate min and max for 'y_next' from the original unscaled data (df_orig)\n","#   # This allows us to manually inverse transform the single predicted value.\n","#   # min_y_next_orig = df_orig['y_next_orig'].min()\n","#   # max_y_next_orig = df_orig['y_next_orig'].max()\n","#   # Inverse transform the scaled prediction using the min-max formula\n","#   #np.array(future_predictions) * (max_y_next_orig - min_y_next_orig) + min_y_next_orig\n","#   unscaled_future_predictions = X_scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n","\n","#   print(f\"Using {winning_model_name} and {winning_model_features} to predicti the next {future_days} days:\")\n","#   print(f\"-------------------------------------------\")\n","#   for i, p in enumerate(unscaled_future_predictions, start=1):\n","#     # Convert last_historical_day to datetime object and add days\n","#     prediction_date = pd.to_datetime(last_historical_day) + pd.offsets.BDay(i)\n","#     print(f\"{prediction_date.strftime('%Y-%m-%d')}: {float(p):.2f}\")"],"metadata":{"id":"K1Qbdh5p--nO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for stock in project_config['STOCKS']:\n","\n","  project_config['TKL'] = stock\n","\n","  results_df, dates_test, unscaled_y_test = race_models(project_config['TKL'], project_config['RACING_MODELS'].split())\n","  plot_results(results_df, dates_test, unscaled_y_test)\n","\n","  print(f\"AND THE WINNER for {project_config['TKL']} IS ...\")\n","  display(results_df[['model_name', 'X_cols', 'mae', 'r2']].sort_values(by='mae', ascending=True))\n","\n","  winning_model = results_df.sort_values(by='mae', ascending=True).iloc[0].model\n","  winning_model_name = results_df.sort_values(by='mae', ascending=True).iloc[0].model_name\n","  winning_model_features = results_df.sort_values(by='mae', ascending=True).iloc[0].X_cols\n","\n","  model_path = f\"{os.getenv('PROJECT_PATH')}{project_config['pickles_directory']}{project_config['TKL']}.model.{winning_model_name}.{winning_model_features}.keras\"\n","  df_path = f\"{os.getenv('PROJECT_PATH')}{project_config['pickles_directory']}{project_config['TKL']}.df.pkl\"\n","  df_orig_path = f\"{os.getenv('PROJECT_PATH')}{project_config['pickles_directory']}{project_config['TKL']}.df_orig.pkl\"\n","\n","  winning_model.save(model_path)\n","  df[ ['Date','y_next']+winning_model_features ].to_pickle(df_path)\n","  df_orig[ ['Date','y_next']+winning_model_features ].to_pickle(df_orig_path)"],"metadata":{"id":"-gVNOS9o6kUF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_next_days(df, model, model_name, model_features, future_days=10):\n","\n","  X_train, X_test, y_train, y_test, dates_test = make_datasets(df, winning_model_features, y_col)\n","\n","  last_historical_block = X_test[-1:] # Select the last sequence from X_test\n","  last_historical_day = df.iloc[-1].Date\n","  future_rolling_block = last_historical_block.copy()\n","  future_predictions = []\n","\n","  for _ in range(future_days):\n","\n","    next_pred_day = model.predict(future_rolling_block)[0]\n","    future_predictions.append(next_pred_day)\n","\n","    new_input_row = future_rolling_block[0, -1, :].copy() # Copy last row of features\n","    new_input_row[0] = next_pred_day # Update the 'y' feature (first feature)\n","    future_rolling_block = np.roll(future_rolling_block, -1, axis=1) # Shift time window\n","    future_rolling_block[0, -1, :] = new_input_row # Place the new feature vector at the end\n","\n","    min_y_next_orig = df_orig['y_next_orig'].min()\n","    max_y_next_orig = df_orig['y_next_orig'].max()\n","    np.array(future_predictions) * (max_y_next_orig - min_y_next_orig) + min_y_next_orig\n","\n","  #print(f\"Using {winning_model_name} and {winning_model_features} to predicti the next {future_days} days:\")\n","  #print(f\"-------------------------------------------\")\n","  for i, p in enumerate(unscaled_future_predictions, start=1):\n","    # Convert last_historical_day to datetime object and add days\n","    prediction_date = pd.to_datetime(last_historical_day) + pd.offsets.BDay(i)\n","    print(f\"{prediction_date.strftime('%Y-%m-%d')}: {float(p):.2f}\")"],"metadata":{"id":"T8AMYLxxzIN6","executionInfo":{"status":"ok","timestamp":1766087584329,"user_tz":-120,"elapsed":237,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}}},"execution_count":215,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","pickles_path = Path(f\"{os.getenv('PROJECT_PATH')}{project_config['pickles_directory']}\")\n","folder = Path(pickles_path)\n","\n","for TKL in project_config['STOCKS']:\n","  project_config['TKL'] = TKL\n","\n","  if list(folder.glob(f\"{TKL}.model*.keras\")) != []:\n","\n","    import ast\n","    model_path = list(folder.glob(f\"{TKL}.model*.keras\"))[0]\n","    df_path = list(folder.glob(f\"{TKL}.df.pkl\"))[0]\n","    df_orig_path = list(folder.glob(f\"{TKL}.df_orig.pkl\"))[0]\n","\n","    fname = model_path.name  # extract filename only\n","    base = fname.removesuffix(\".keras\")\n","    tkl_name, _, best_model_name, features_str = base.split(\".\", maxsplit=3)\n","    best_model_features = ast.literal_eval(features_str)\n","\n","    print(f\"TKL: {tkl_name}\")\n","    print(f\"Model: {best_model_name}\")\n","    print(f\"Features: {best_model_features}\")\n","\n","    import tensorflow as tf\n","    df = pd.read_pickle(df_path)\n","    df_orig = pd.read_pickle(df_orig_path)\n","    best_model = tf.keras.models.load_model(model_path)\n","\n","    display(df.tail(1), df_orig.tail(1))\n","    best_model.summary()\n","\n","    predict_next_days(df, best_model, best_model_name, best_model_features, future_days=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":982},"id":"xOMjYJkS0Rm_","executionInfo":{"status":"error","timestamp":1766087592946,"user_tz":-120,"elapsed":5793,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}},"outputId":"4900237e-9cae-4c5d-fe59-0a2a5eec5bf1"},"execution_count":216,"outputs":[{"output_type":"stream","name":"stdout","text":["TKL: AAPL\n","Model: GRU\n","Features: ['Oil', 'y', 'NASDAQ']\n"]},{"output_type":"display_data","data":{"text/plain":["            Date    y_next       Oil         y    NASDAQ\n","4822  2025-12-15  0.959219  0.516346  0.957458  0.960288"],"text/html":["\n","  <div id=\"df-d3450eaf-89d6-4658-a421-0126c98fd0fa\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>y_next</th>\n","      <th>Oil</th>\n","      <th>y</th>\n","      <th>NASDAQ</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4822</th>\n","      <td>2025-12-15</td>\n","      <td>0.959219</td>\n","      <td>0.516346</td>\n","      <td>0.957458</td>\n","      <td>0.960288</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3450eaf-89d6-4658-a421-0126c98fd0fa')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d3450eaf-89d6-4658-a421-0126c98fd0fa button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d3450eaf-89d6-4658-a421-0126c98fd0fa');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["            Date    y_next       Oil         y    NASDAQ\n","4822  2025-12-15  0.959219  0.516346  0.957458  0.960288"],"text/html":["\n","  <div id=\"df-64035865-c123-4d6b-9bb5-281854768f71\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>y_next</th>\n","      <th>Oil</th>\n","      <th>y</th>\n","      <th>NASDAQ</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4822</th>\n","      <td>2025-12-15</td>\n","      <td>0.959219</td>\n","      <td>0.516346</td>\n","      <td>0.957458</td>\n","      <td>0.960288</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64035865-c123-4d6b-9bb5-281854768f71')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-64035865-c123-4d6b-9bb5-281854768f71 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-64035865-c123-4d6b-9bb5-281854768f71');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_33\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_33\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ gru_49 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │         \u001b[38;5;34m8,250\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ gru_50 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,860\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ gru_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,250</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ gru_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,860</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,365\u001b[0m (118.62 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,365</span> (118.62 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,121\u001b[0m (39.54 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,121</span> (39.54 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m20,244\u001b[0m (79.08 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,244</span> (79.08 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step\n"]},{"output_type":"error","ename":"KeyError","evalue":"'y_next_orig'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'y_next_orig'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3088174053.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mpredict_next_days\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_days\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-1889686127.py\u001b[0m in \u001b[0;36mpredict_next_days\u001b[0;34m(df, model, model_name, model_features, future_days)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfuture_rolling_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_input_row\u001b[0m \u001b[0;31m# Place the new feature vector at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmin_y_next_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_orig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_next_orig'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mmax_y_next_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_orig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_next_orig'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_predictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_y_next_orig\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_y_next_orig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmin_y_next_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'y_next_orig'"]}]},{"cell_type":"code","source":["df_orig"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"p5Gnbpb-Bo7G","executionInfo":{"status":"ok","timestamp":1766087633085,"user_tz":-120,"elapsed":257,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}},"outputId":"a2bb0583-5585-4bd3-94b0-bd2e11ddad18"},"execution_count":217,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Date    y_next       Oil         y    NASDAQ\n","0     2006-10-18  0.000471  0.520883  0.000000  0.047092\n","1     2006-10-19  0.000572  0.525530  0.000471  0.047259\n","2     2006-10-20  0.000732  0.516346  0.000572  0.047319\n","3     2006-10-23  0.000689  0.527225  0.000732  0.047903\n","4     2006-10-24  0.000755  0.530177  0.000689  0.047431\n","...          ...       ...       ...       ...       ...\n","4818  2025-12-09  0.973904  0.524164  0.968270  0.983165\n","4819  2025-12-10  0.971263  0.525312  0.973904  0.986588\n","4820  2025-12-11  0.972143  0.520610  0.971263  0.983931\n","4821  2025-12-12  0.957458  0.519735  0.972143  0.966359\n","4822  2025-12-15  0.959219  0.516346  0.957458  0.960288\n","\n","[4823 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-774369fd-df90-4c42-bfb0-bba44cea07f3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>y_next</th>\n","      <th>Oil</th>\n","      <th>y</th>\n","      <th>NASDAQ</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2006-10-18</td>\n","      <td>0.000471</td>\n","      <td>0.520883</td>\n","      <td>0.000000</td>\n","      <td>0.047092</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2006-10-19</td>\n","      <td>0.000572</td>\n","      <td>0.525530</td>\n","      <td>0.000471</td>\n","      <td>0.047259</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2006-10-20</td>\n","      <td>0.000732</td>\n","      <td>0.516346</td>\n","      <td>0.000572</td>\n","      <td>0.047319</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2006-10-23</td>\n","      <td>0.000689</td>\n","      <td>0.527225</td>\n","      <td>0.000732</td>\n","      <td>0.047903</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2006-10-24</td>\n","      <td>0.000755</td>\n","      <td>0.530177</td>\n","      <td>0.000689</td>\n","      <td>0.047431</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4818</th>\n","      <td>2025-12-09</td>\n","      <td>0.973904</td>\n","      <td>0.524164</td>\n","      <td>0.968270</td>\n","      <td>0.983165</td>\n","    </tr>\n","    <tr>\n","      <th>4819</th>\n","      <td>2025-12-10</td>\n","      <td>0.971263</td>\n","      <td>0.525312</td>\n","      <td>0.973904</td>\n","      <td>0.986588</td>\n","    </tr>\n","    <tr>\n","      <th>4820</th>\n","      <td>2025-12-11</td>\n","      <td>0.972143</td>\n","      <td>0.520610</td>\n","      <td>0.971263</td>\n","      <td>0.983931</td>\n","    </tr>\n","    <tr>\n","      <th>4821</th>\n","      <td>2025-12-12</td>\n","      <td>0.957458</td>\n","      <td>0.519735</td>\n","      <td>0.972143</td>\n","      <td>0.966359</td>\n","    </tr>\n","    <tr>\n","      <th>4822</th>\n","      <td>2025-12-15</td>\n","      <td>0.959219</td>\n","      <td>0.516346</td>\n","      <td>0.957458</td>\n","      <td>0.960288</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4823 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-774369fd-df90-4c42-bfb0-bba44cea07f3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-774369fd-df90-4c42-bfb0-bba44cea07f3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-774369fd-df90-4c42-bfb0-bba44cea07f3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-a4b56a06-7615-48cd-9b75-6bf102cc9a41\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4b56a06-7615-48cd-9b75-6bf102cc9a41')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-a4b56a06-7615-48cd-9b75-6bf102cc9a41 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_2c145287-8dc9-43bf-bc79-595c708c1cf1\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_orig')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_2c145287-8dc9-43bf-bc79-595c708c1cf1 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_orig');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_orig","summary":"{\n  \"name\": \"df_orig\",\n  \"rows\": 4823,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 4823,\n        \"samples\": [\n          \"2023-07-06\",\n          \"2013-06-11\",\n          \"2025-12-10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_next\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2580823002332859,\n        \"min\": 0.0003876186897255,\n        \"max\": 1.0,\n        \"num_unique_values\": 4734,\n        \"samples\": [\n          0.074365188574304,\n          0.0077059646069696,\n          0.0554373333007621\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Oil\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11819174272598394,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3609,\n        \"samples\": [\n          0.6546578149504314,\n          0.492018383871713,\n          0.4254865746405333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.257882516472124,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4734,\n        \"samples\": [\n          0.0731597067163362,\n          0.0079214252194406,\n          0.0547096377774961\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NASDAQ\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24114797071346503,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4801,\n        \"samples\": [\n          0.0,\n          0.7595494948857942,\n          0.2231991189911603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":217}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJhrZFbGk+TBf0utkjhVwS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}