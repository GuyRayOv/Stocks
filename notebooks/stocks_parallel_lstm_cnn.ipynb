{"cells":[{"cell_type":"markdown","metadata":{"id":"4Ns2SNtAqGwM"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hjNT5fdaAq2u"},"outputs":[],"source":["import sys\n","import os\n","from google.colab import drive\n","from google.colab import files\n","from dotenv import load_dotenv\n","import json\n","import warnings\n","import pickle\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","warnings.filterwarnings(\"ignore\")\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"DRGyC6FrqbZA"},"source":["# Bootstrap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gch0QCmZIG5C"},"outputs":[],"source":["np.random.seed(31071967)\n","\n","# Find and load the .env file from the current or parent directories\n","load_dotenv()\n","\n","drive.mount('/content/drive')\n","\n","with open(f\"{os.getenv('PROJECT_PATH')}/src/config.json\", 'r') as f:\n","    project_config = json.load(f)\n","    project_config.pop('_comment', None)\n","    project_config.pop('_note', None)\n","    f.close()"]},{"cell_type":"markdown","source":["# Load dataset file of current TKL"],"metadata":{"id":"j6X7iNBA80O3"}},{"cell_type":"code","source":["print(f\"Loading dataset for {project_config['TKL']} .....\\n\")\n","\n","DATASET = f\"{os.getenv('PROJECT_PATH')}{project_config['data_directory']}{project_config['TKL']}.df.csv\"\n","df_all = pd.read_csv(DATASET, index_col=False)\n","df_all = df_all.drop(columns=[\"Unnamed: 0\"])\n","\n","cols_orig = [col for col in df_all.columns if col.endswith('_orig')]\n","cols_normalized = [col for col in df_all.columns if not col.endswith('_orig')]\n","\n","df = df_all[cols_normalized]\n","df_orig = df_all[['Date'] + cols_orig]\n","\n","print(f\"\\ndf for training\")\n","print(f\"-----------------\")\n","display(df.tail(1))\n","\n","print(f\"\\ndf for visualization\")\n","print(f\"----------------------\")\n","display(df_orig.tail(1))"],"metadata":{"id":"kZNVRwh78gCz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data prep"],"metadata":{"id":"zcp4t8WgCz-0"}},{"cell_type":"code","source":["def make_datasets(df, X_cols, y_col):\n","\n","    LOOK_BACK_DAYS = int(project_config['LOOK_BACK_DAYS'])\n","\n","    X, y = [], []\n","\n","    for i in range(LOOK_BACK_DAYS, len(df)):\n","        X.append(df.loc[i-LOOK_BACK_DAYS:i-1, X_cols].values)\n","        y.append(df.loc[i, y_col].values[0])\n","    X = np.array(X, dtype=np.float32)\n","    y = np.array(y, dtype=np.float32)\n","    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n","\n","    split = int(0.9 * len(X))\n","\n","    X_train, X_test = X[:split], X[split:]\n","    y_train, y_test = y[:split], y[split:]\n","\n","    dates = pd.to_datetime(df['Date'])\n","    dates_test = dates[-len(y_test):].values\n","\n","    return X_train, X_test, y_train, y_test, dates_test"],"metadata":{"id":"MGNujJS1EEvV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_predict(X_train, X_test, y_train, y_test, model_name, epochs=0, batch_size=0):\n","\n","  from tensorflow.keras.models import Sequential\n","  from tensorflow.keras.layers import LSTM, Dense, GRU\n","\n","  epochs = int(project_config['TRAIN_EPOCS']) if epochs == 0 else epochs\n","  batch_size = int(project_config['TRAIN_BATCH_SIZE']) if batch_size == 0 else batch_size\n","\n","  if model_name == 'LSTM':\n","    model = Sequential([\n","        LSTM(50, return_sequences=True, input_shape=(X_train.shape[1],X_train.shape[2])),\n","        LSTM(10),\n","        Dense(1)\n","    ])\n","\n","  if model_name == 'GRU':\n","    model = Sequential([\n","      GRU(50, return_sequences=True, input_shape=(X_train.shape[1],X_train.shape[2])),\n","      GRU(10),\n","      Dense(1)\n","    ])\n","\n","  model.compile(optimizer='adam', loss='mse')\n","\n","  history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n","\n","  pred = model.predict(X_test)\n","\n","  # Calculate min and max for 'y_next' from the original unscaled data (df_orig)\n","  # This allows us to manually inverse transform the single predicted value.\n","  min_y_next_orig = df_orig['y_next_orig'].min()\n","  max_y_next_orig = df_orig['y_next_orig'].max()\n","\n","  # Inverse transform the scaled prediction using the min-max formula\n","  unscaled_prediction = pred * (max_y_next_orig - min_y_next_orig) + min_y_next_orig\n","  unscaled_y_test = y_test * (max_y_next_orig - min_y_next_orig) + min_y_next_orig\n","\n","  print(f\"{model_name} {X_cols}\")\n","\n","  from sklearn.metrics import mean_absolute_error\n","  mae = mean_absolute_error(unscaled_y_test, unscaled_prediction)\n","  print(f\"MAE: {mae:.4f}\")\n","\n","  from sklearn.metrics import r2_score\n","  r2 = r2_score(unscaled_y_test, unscaled_prediction)\n","  print(f\"RÂ²: {r2:.4f}\")\n","\n","  return unscaled_prediction, unscaled_y_test, model"],"metadata":{"id":"ANWmCT8mGhci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_cols_full = [col for col in df.columns if col not in ['Date','y_next']]\n","X_cols_exho = [col for col in df.columns if '_' not in col and col != 'Date']\n","X_cols_tkl  = ['y']\n","y_col       = ['y_next']"],"metadata":{"id":"2cGh7McfuF7p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LSTM vs. GRU"],"metadata":{"id":"1mdgtG0Or5WN"}},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import r2_score\n","\n","results_df = pd.DataFrame(columns=[ \"model_name\", \"X_cols\",  \"prediction\", \"mae\", \"r2\", \"model\" ])\n","\n","for X_cols in [X_cols_full, X_cols_exho, X_cols_tkl]:\n","\n","  X_train, X_test, y_train, y_test, dates_test = make_datasets(df, X_cols, y_col)\n","\n","  unscaled_prediction, unscaled_y_test, model = train_predict(X_train, X_test, y_train, y_test, model_name=\"GRU\")\n","  results_df.loc[len(results_df)] = {\n","    \"model_name\": \"GRU\",\n","    \"X_cols\": X_cols,\n","    \"prediction\": unscaled_prediction,\n","    \"mae\": mean_absolute_error(unscaled_y_test, unscaled_prediction),\n","    \"r2\": r2_score(unscaled_y_test, unscaled_prediction),\n","    \"model\": model\n","  }\n","\n","  unscaled_prediction, unscaled_y_test, model = train_predict(X_train, X_test, y_train, y_test, model_name=\"LSTM\")\n","  results_df.loc[len(results_df)] = {\n","    \"model_name\": \"LSTM\",\n","    \"X_cols\": X_cols,\n","    \"prediction\": unscaled_prediction,\n","    \"mae\": mean_absolute_error(unscaled_y_test, unscaled_prediction),\n","    \"r2\": r2_score(unscaled_y_test, unscaled_prediction),\n","    \"model\": model\n","  }"],"metadata":{"id":"jwaRKpLaPW-Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_results(results_df):\n","\n","  import matplotlib.dates as mdates # Added import\n","\n","  for model_name in results_df.model_name.unique():\n","    plt.figure(figsize=(18,9))\n","    plt.title(f\"{project_config['TKL']} {model_name}\")\n","    # Note: unscaled_y_test and dates_test are assumed to be defined in the global scope\n","    # and represent the test data for comparison with all predictions.\n","    plt.plot(dates_test, unscaled_y_test, label=f\"Actual\")\n","\n","    # Corrected iteration: iterate over rows using .iterrows()\n","    for index, entry in results_df[results_df.model_name == model_name].iterrows():\n","      plt.plot(dates_test, entry.prediction, label=f\"features: {entry.X_cols}\")\n","\n","    ax = plt.gca()\n","    ax.xaxis.set_major_locator(mdates.MonthLocator())\n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n","\n","    plt.xticks(rotation=45)\n","    plt.tight_layout()\n","\n","    plt.legend()\n","    plt.show()\n","\n","  # Convert lists in 'X_cols' to tuples for unique identification\n","  # This is necessary because lists are unhashable, causing TypeError with .unique()\n","  results_df['X_cols_tuple'] = results_df['X_cols'].apply(tuple)\n","\n","  for features_tuple in results_df.X_cols_tuple.unique():\n","    plt.figure(figsize=(18,9))\n","    # Convert tuple back to list for display purposes in the title\n","    features = list(features_tuple)\n","    plt.title(f\"{project_config['TKL']} {features}\")\n","    # Note: unscaled_y_test and dates_test are assumed to be defined in the global scope\n","    # and represent the test data for comparison with all predictions.\n","    plt.plot(dates_test, unscaled_y_test, label=f\"Actual\")\n","\n","    # Corrected iteration: iterate over rows using .iterrows()\n","    for index, entry in results_df[results_df.X_cols_tuple == features_tuple].iterrows():\n","      plt.plot(dates_test, entry.prediction, label=f\":{entry.model_name}\")\n","\n","    ax = plt.gca()\n","    ax.xaxis.set_major_locator(mdates.MonthLocator())\n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n","\n","    plt.xticks(rotation=45)\n","    plt.tight_layout()\n","\n","    plt.legend()\n","    plt.show()"],"metadata":{"id":"kCf0K2YbX2yl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_results(results_df)"],"metadata":{"id":"nfoGvOltdnx8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"AND THE WINNER for {project_config['TKL']} IS ...\")\n","results_df.sort_values(by='mae', ascending=True).iloc[0]"],"metadata":{"id":"zdCf0TFQU7AG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["winning_model = results_df.sort_values(by='mae', ascending=True).iloc[0].model\n","winning_model_name = results_df.sort_values(by='mae', ascending=True).iloc[0].model_name\n","model_path = f\"{os.getenv('PROJECT_PATH')}{project_config['pickles_directory']}{project_config['TKL']}.model.{winning_model_name}.keras\"\n","winning_model.save(model_path)"],"metadata":{"id":"ZPDYHiWTr1iL"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbygok5dvEdHe1ppu3rPcP"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}