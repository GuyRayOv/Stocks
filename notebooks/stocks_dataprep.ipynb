{"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"vy7LcUPlsK0X"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbWvCAKmUQD6"},"outputs":[],"source":["import sys\n","import os\n","from google.colab import drive\n","from google.colab import files\n","from dotenv import load_dotenv\n","import json\n","import warnings\n","import pickle\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","warnings.filterwarnings(\"ignore\")\n","%matplotlib inline"]},{"cell_type":"markdown","source":["# Bootstrap"],"metadata":{"id":"zdP_xX80sN98"}},{"cell_type":"code","source":["np.random.seed(31071967)"],"metadata":{"id":"qw-4Y4FPTO-a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find and load the .env file from the current or parent directories\n","load_dotenv()\n","\n","drive.mount('/content/drive')\n","\n","with open(f\"{os.getenv('PROJECT_PATH')}/src/config.json\", 'r') as f:\n","    project_config = json.load(f)\n","    project_config.pop('_comment', None)\n","    project_config.pop('_note', None)\n","    f.close()"],"metadata":{"id":"jsWS0uXZwymE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sanity check\n","project_config[\"TKL\"]"],"metadata":{"id":"X_dsR2Ov4Zk5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Download TKL data from YF"],"metadata":{"id":"JcreNdJF7kFy"}},{"cell_type":"code","source":["from datetime import date, timedelta\n","end_date = date.today() - timedelta(days=1)\n","start_date = end_date - timedelta(days=int(project_config[\"HISTORY_DEPTH\"]))"],"metadata":{"id":"ZIHTgHdxaSzQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tickers_yf = {\n","    \"y_today\"     : f\"{project_config['TKL']}\",\n","    \"NASDAQ\"      : \"^IXIC\",\n","    \"SP500\"       : \"^GSPC\",\n","    \"RealEstate\"  : \"VNQ\",\n","    \"Oil_WTI\"     : \"CL=F\",\n","    \"Gold\": \"GC=F\"\n","}\n","\n","tickers_fred = {\n","   # \"Inflation_CPI\" : \"CPIAUCSL\",\n","   # \"Unemployment\"  : \"UNRATE\"\n","}"],"metadata":{"id":"Nsr0rFkraP2M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import yfinance as yf\n","import pandas as pd\n","from pandas_datareader import data as pdr\n","\n","# ---- DOWNLOAD FROM YAHOO FINANCE ----\n","ts_yf = yf.download(\n","    tickers=list(tickers_yf.values()),\n","    start=start_date,\n","    end=end_date,\n","    auto_adjust=True\n",")[\"Close\"]\n","\n","# rename columns to readable names\n","ts_yf.columns = list(tickers_yf.keys())\n","\n","# ---- DOWNLOAD FROM FRED ----\n","ts_fred = pd.DataFrame()\n","for name, fred_code in tickers_fred.items():\n","    ts_fred[name] = pdr.DataReader(fred_code, \"fred\", start_date, end_date)\n","\n","\n","# ---- MERGE ALL ----\n","ts = pd.concat([ts_yf, ts_fred], axis=1)\n","\n","# Fill missing daily values for macro data (monthly)\n","ts = ts.ffill()  # forward fill\n","ts = ts.dropna()  # drop any remaining rows\n","\n","ts = ts.reset_index().rename(columns={\"Date\": \"Date\"})\n","\n","display(ts.head(1))\n","display(ts.tail(1))"],"metadata":{"id":"mw8oYHvVZsEY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Turn time series into supprvied learning table"],"metadata":{"id":"k8orD4C3YpKN"}},{"cell_type":"code","source":["lags = [1,5,10,22,65] # lookback days\n","windows =  [5,10,22,65] # statistics windows\n","\n","df = ts.copy()\n","\n","# Identify columns to generate features for (excluding 'Date')\n","feature_base_cols = [c for c in df.columns if c not in ['Date']]\n","\n","for base_col in feature_base_cols: # Iterate over TKL cols\n","\n","  # Generate lagged features for the current base_col\n","  for lag in lags:\n","    df[f\"{base_col}_lag_{lag}\"] = df[base_col].shift(lag)\n","\n","  # Generate rolling window statistics for the current base_col\n","  for window in windows:\n","    df[f\"{base_col}_min_{window}\"] = df[base_col].rolling(window=window).min()\n","    df[f\"{base_col}_max_{window}\"] = df[base_col].rolling(window=window).max()\n","    df[f\"{base_col}_mean_{window}\"] = df[base_col].rolling(window=window).mean()\n","    df[f\"{base_col}_std_{window}\"]  = df[base_col].rolling(window=window).std()\n","    df[f\"{base_col}_diff_{window}\"] = df[base_col].diff(window)\n","    df[f\"{base_col}_pct_{window}\"] = df[base_col].pct_change(window)\n","\n","\n","df['y_tomorrow'] = df['y_today'].shift(-1)    # tomorrow's close price\n","df.tail(1)['y_tomorrow'] = -1                 # the TARGET cell\n","tommorw_date = df.tail(1)['Date']\n","\n","\n","df.dropna(inplace=True)\n","\n","# Drop 'Date' column from X, along with 'y' and 'y_next'\n","X = df.drop(['Date','y_tomorrow'], axis=1)\n","y = df['y_tomorrow']"],"metadata":{"id":"EvmwqsAoXG-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = X.iloc[:-2], X.iloc[-1:]\n","y_train, y_test = y.iloc[:-2], y.iloc[-1:]\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"],"metadata":{"id":"iynIeL1ulR4J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train, Predict, Evaluate"],"metadata":{"id":"P2Oqmkp-mI87"}},{"cell_type":"code","source":["from xgboost import XGBRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","xgb = XGBRegressor(\n","    n_estimators=300,\n","    max_depth=5,\n","    learning_rate=0.05,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    objective=\"reg:squarederror\")\n","\n","xgb.fit(X_train, y_train)"],"metadata":{"id":"HoYw9Xi9mASg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred = xgb.predict(X_test)\n","mae = mean_absolute_error(y_test, pred)\n","print(\"MAE:\", mae)"],"metadata":{"id":"EnRMoVhanbkD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["last_row = X_test # Use X_test which was successfully predicted upon\n","tomorrow_prediction = xgb.predict(last_row)[0]\n","print(f\"Stoke: {project_config['TKL']}\")\n","print(f\"Date: {tommorw_date.iloc[0].date()}\")\n","print(f\"Close Prediction: ${tomorrow_prediction:.2f}\")"],"metadata":{"id":"UTloMMYAnTNp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Feature selection"],"metadata":{"id":"GBZeXSO_rQqv"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import xgboost # Import the xgboost module\n","\n","# Plot feature importance based on \"weight\" (number of times a feature appears in a tree)\n","plt.figure(figsize=(10, 6))\n","xgboost.plot_importance(xgb, max_num_features=20) # Pass the xgb regressor object\n","plt.title(\"Feature Importance (Weight)\")\n","plt.show()\n","\n","# Get the feature importance dictionary\n","# importance_type can be 'weight', 'gain', or 'cover'\n","importance_dict = xgb.get_booster().get_score(importance_type='weight')\n","\n","# 2. Convert to a Pandas DataFrame for easy sorting and viewing\n","df_importance = pd.DataFrame(list(importance_dict.items()), columns=['Feature', 'Score'])\n","\n","# 3. Sort by Score (High to Low)\n","df_importance = df_importance.sort_values(by='Score', ascending=False)\n","\n","# 4. Extract just the names into a Python list (for use in code)\n","top_weight_features_list = df_importance['Feature'].head(15).tolist()\n","print(top_weight_features_list)"],"metadata":{"id":"XyRoLkmynur4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# OPTIONAL: Plot based on \"gain\" (average gain of splits which use the feature)\n","# \"Gain\" is often more accurate for finding what actually drives the prediction.\n","plt.figure(figsize=(10, 6))\n","xgboost.plot_importance(xgb, importance_type='gain', max_num_features=20) # Pass the xgb regressor object\n","plt.title(\"Feature Importance (Gain)\")\n","plt.show()\n","\n","# Get the feature importance dictionary\n","# importance_type can be 'weight', 'gain', or 'cover'\n","importance_dict = xgb.get_booster().get_score(importance_type='gain')\n","\n","# 2. Convert to a Pandas DataFrame for easy sorting and viewing\n","df_importance = pd.DataFrame(list(importance_dict.items()), columns=['Feature', 'Score'])\n","\n","# 3. Sort by Score (High to Low)\n","df_importance = df_importance.sort_values(by='Score', ascending=False)\n","\n","# 4. Extract just the names into a Python list (for use in code)\n","top_gain_features_list = df_importance['Feature'].head(15).tolist()\n","print(top_gain_features_list)"],"metadata":{"id":"A6iSN9ORDNl9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_features = list(set(top_gain_features_list) | set(top_weight_features_list))\n","top_features"],"metadata":{"id":"QFXccHsOFtaf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Final df"],"metadata":{"id":"aNvZPouorV0Q"}},{"cell_type":"code","source":["final_df = df[['Date','y_tomorrow','y_today'] + top_features]\n","final_df"],"metadata":{"id":"Z3VS6_y9K-9B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pickle, CSV"],"metadata":{"id":"-Rl3qzjtraC6"}},{"cell_type":"code","source":["df_pickle_path = f\"{os.getenv('PROJECT_PATH')}{project_config['pickles_directory']}{project_config['TKL']}.df.pkl\"\n","df_csv_path = f\"{os.getenv('PROJECT_PATH')}{project_config['data_directory']}{project_config['TKL']}.df.csv\"\n","\n","final_df.to_pickle(df_pickle_path)\n","final_df.to_csv(df_csv_path)"],"metadata":{"id":"eQoUheoTLYV4"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1z_z6aKOseMCo3v_YjFnMhl-K4gXimAMR","authorship_tag":"ABX9TyMwunhnJn6XJ2VhDOgmZVg7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}