{"cells":[{"cell_type":"markdown","metadata":{"id":"4Ns2SNtAqGwM"},"source":["# Imports"]},{"cell_type":"code","source":["import sys\n","import os\n","import json\n","import warnings\n","import pickle\n","from dotenv import load_dotenv\n","\n","!pip install -U google-generativeai\n","import google.generativeai as genai\n","\n","from google.colab import drive\n","from google.colab import files\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","!pip install papermill\n","!pip install nbconvert\n","!pip install nbformat\n","!pip install IPython\n","\n","import papermill as pm\n","import nbformat\n","from nbconvert import HTMLExporter\n","from IPython.display import HTML, display\n","\n","warnings.filterwarnings(\"ignore\")\n","%matplotlib inline"],"metadata":{"id":"C_cNhJMevvae","executionInfo":{"status":"aborted","timestamp":1766601507211,"user_tz":-120,"elapsed":32436,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DRGyC6FrqbZA"},"source":["# Bootstrap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1d9o7FkEb0h","executionInfo":{"status":"aborted","timestamp":1766601507212,"user_tz":-120,"elapsed":32434,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}}},"outputs":[],"source":["np.random.seed(31071967)\n","\n","load_dotenv()\n","\n","drive.mount('/content/drive')\n","\n","with open(f\"{os.getenv('PROJECT_PATH')}/src/config.json\", 'r') as f:\n","    project_config = json.load(f)\n","    project_config.pop('_comment', None)\n","    project_config.pop('_note', None)\n","    f.close()"]},{"cell_type":"code","source":["# Define our GOOGLE API KEY  in .env file. GOOGLE_API_KEY=<your api key>\n","genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"],"metadata":{"id":"SEXFQpYlC-uA","executionInfo":{"status":"aborted","timestamp":1766601507215,"user_tz":-120,"elapsed":32433,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_best_available_model():\n","    \"\"\"\n","    FORCE uses the specific stable version 'gemini-1.5-flash'.\n","    We avoid 'listing' models because that finds restricted experimental versions.\n","    \"\"\"\n","    # This is the exact name of the stable, free-tier friendly model.\n","    # We return it directly to stop the code from picking \"2.5\" or \"latest\".\n","    return \"gemini-1.5-flash\""],"metadata":{"id":"WeOIP9qglEL-","executionInfo":{"status":"aborted","timestamp":1766601507217,"user_tz":-120,"elapsed":32433,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_prediction_params(user_sentence):\n","    # 1. Dynamically get the model name\n","    model_name = get_best_available_model()\n","\n","    if not model_name:\n","        print(\"CRITICAL ERROR: No valid Gemini models found for your API key.\")\n","        return None\n","\n","    print(f\"[System] Using model: {model_name}\")\n","    model = genai.GenerativeModel(model_name)\n","\n","    prompt = f\"\"\"\n","    You are a data extraction assistant.\n","    Analyze this user request: \"{user_sentence}\"\n","\n","    Extract:\n","    1. \"stock_ticker\": The ticker symbol (e.g., \"Apple\" -> \"AAPL\").\n","    2. \"days\": The integer number of days for prediction (e.g., \"2 weeks\" -> 14).\n","\n","    Return ONLY raw JSON. Keys: 'stock_ticker', 'days'.\n","    \"\"\"\n","\n","    try:\n","        # Note: We removed 'response_mime_type' just in case your library version is old.\n","        # We will handle the JSON manually.\n","        response = model.generate_content(prompt)\n","\n","        # Clean up the text to ensure it's valid JSON (remove markdown backticks)\n","        clean_text = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n","        data = json.loads(clean_text)\n","        return data\n","\n","    except Exception as e:\n","        print(f\"Error extracting data: {e}\")\n","        return None"],"metadata":{"id":"1IbzNgnK8nMm","executionInfo":{"status":"aborted","timestamp":1766601507219,"user_tz":-120,"elapsed":32434,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_target_tkl_from_user():\n","\n","  user_input = input(\"What would you like to predict and for how long: \") # e.g. \"Predict Google for 2 weeks\"\n","  result = extract_prediction_params(user_input)\n","\n","  while not result or result == None or result.get('stock_ticker') == None:\n","    print(\"\\nFailed to understand the proment. Please try again.\")\n","    user_input = input(\"\\nRequest: \")\n","    result = extract_prediction_params(user_input)\n","\n","  return result"],"metadata":{"id":"t7aE8viSI6Pl","executionInfo":{"status":"aborted","timestamp":1766601507220,"user_tz":-120,"elapsed":32433,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def update_param_in_projet_config_file(param, new_value, file_path=f\"{os.getenv('PROJECT_PATH')}/src/config.json\"):\n","\n","    # 1. Check if file exists, if not, create a placeholder\n","    if not os.path.exists(file_path):\n","        print(f\"[Warning] {file_path} not found. Creating a new one.\")\n","        data = {}\n","    else:\n","        # 2. Read the existing data\n","        try:\n","            with open(file_path, 'r') as f:\n","                data = json.load(f)\n","        except json.JSONDecodeError:\n","            print(f\"[Error] {file_path} is empty or corrupted. Starting fresh.\")\n","            data = {}\n","\n","    # 3. Update the specific variable\n","    data[param] = new_value\n","\n","    # 4. Write everything back to the file\n","    with open(file_path, 'w') as f:\n","        json.dump(data, f, indent=4) # indent=4 makes it readable for humans\n","\n","    print(f\"Successfully updated {param} to: {new_value}\")"],"metadata":{"id":"fbv5VWfCKtb3","executionInfo":{"status":"aborted","timestamp":1766601507228,"user_tz":-120,"elapsed":32439,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_notebook(notebook_name, output_name, parameters=None):\n","\n","  # --- Execute the proviuse notebook with parameters ---\n","  pm.execute_notebook(\n","      input_path = notebook_name,\n","      output_path = output_name,\n","      log_output=False,  # don't print logs while running\n","      progress_bar=True\n","  )\n","\n","  # --- Convert the executed notebook to HTML ---\n","  nb = nbformat.read(output_name, as_version=4)\n","  html_exporter = HTMLExporter()\n","  html_exporter.template_name = \"lab\"  # modern look; alternatives: 'classic', 'basic'\n","  body, _ = html_exporter.from_notebook_node(nb)\n","\n","  # --- Display the HTML result inline ---\n","  display(HTML(body))"],"metadata":{"id":"uNo88yYdOhIF","executionInfo":{"status":"aborted","timestamp":1766601507230,"user_tz":-120,"elapsed":32440,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(user_selected_tkl, user_selected_days):\n","\n","  project_config['TKL'] = user_selected_tkl\n","  update_param_in_projet_config_file('TKL', user_selected_tkl)\n","  project_config['PRED.DAYS'] = user_selected_days\n","  update_param_in_projet_config_file('PRED.DAYS', user_selected_days)\n","\n","  input_file = f\"{os.getenv('PROJECT_PATH')}{project_config['notebooks_directory']}{project_config['notebook9']}\"\n","  output_file = f\"{os.getenv('PROJECT_PATH')}{project_config['output_directory']}{project_config['TKL']}.{project_config['output9']}\"\n","\n","  run_notebook(input_file, output_file)"],"metadata":{"id":"9S3J_FwvOh7E","executionInfo":{"status":"aborted","timestamp":1766601507231,"user_tz":-120,"elapsed":32438,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.generativeai.client import configure\n","print(\"--- Stock Prediction Setup ---\")\n","\n","confirmed_user_params = False\n","while not confirmed_user_params:\n","\n","  result = get_target_tkl_from_user()\n","  days = int(result.get('days')) if result.get('days') != None else int(project_config[\"PRED.DAYS\"])\n","\n","  print(f\"Ticker: {result.get('stock_ticker')}\")\n","  print(f\"Days:   {days}\")\n","\n","  if days < 1 or days > 10:\n","    print(\"Days should be between 1 and 10\")\n","    continue\n","\n","  confirmed_user_params = (input(\"Pls confirm: [y=yes, n=no] \") == 'y')\n","\n","predict(result.get('stock_ticker'), days)"],"metadata":{"id":"BBvX8ay5JVjc","colab":{"base_uri":"https://localhost:8080/","height":864},"executionInfo":{"status":"error","timestamp":1766601507171,"user_tz":-120,"elapsed":209965,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}},"outputId":"bc9e96eb-5245-4dca-ee78-7019aba33ca9"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Stock Prediction Setup ---\n","What would you like to predict and for how long: נוידיאה\n","[System] Scanning for available models...\n","[System] Using model: models/gemini-pro-latest\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tornado.access:429 POST /v1beta/models/gemini-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 534.87ms\n"]},{"output_type":"stream","name":"stdout","text":["Error extracting data: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n","* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\n","* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\n","* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\n","* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\n","Please retry in 47.70035384s.\n","\n","Failed to understand the proment. Please try again.\n","\n","Request: nvidia\n","[System] Scanning for available models...\n","[System] Using model: models/gemini-pro-latest\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tornado.access:429 POST /v1beta/models/gemini-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 3838.02ms\n"]},{"output_type":"stream","name":"stdout","text":["Error extracting data: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n","* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\n","* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\n","* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\n","* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\n","Please retry in 47.149893306s.\n","\n","Failed to understand the proment. Please try again.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-262731470.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfirmed_user_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_target_tkl_from_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mdays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'days'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'days'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PRED.DAYS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1743522011.py\u001b[0m in \u001b[0;36mget_target_tkl_from_user\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stock_ticker'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFailed to understand the proment. Please try again.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nRequest: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_prediction_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","source":["import google.generativeai as genai\n","import json\n","import time\n","\n","# --- CONFIGURATION ---\n","# genai.configure(api_key=\"YOUR_API_KEY\")\n","\n","def get_working_model_name():\n","    \"\"\"\n","    Based on your specific log, we prioritize 'Lite' models\n","    which typically have better availability than 'Preview' models.\n","    \"\"\"\n","    # We search specifically for the model we saw in your log\n","    target_models = [\n","        \"models/gemini-2.0-flash-lite\",      # Best bet for speed/quota\n","        \"models/gemini-2.0-flash-lite-001\",\n","        \"models/gemini-2.0-flash\",           # Second best\n","        \"models/gemini-2.5-flash-lite\"       # Alternative\n","    ]\n","\n","    available = [m.name for m in genai.list_models()]\n","\n","    # Pick the first matching target\n","    for target in target_models:\n","        if target in available:\n","            return target\n","\n","    # Fallback to whatever flash exists if Lite is missing\n","    for m in available:\n","        if \"flash\" in m and \"2.5\" not in m: # Avoid 2.5 if possible\n","            return m\n","\n","    return available[0] # Absolute fallback\n","\n","def extract_prediction_params(user_sentence):\n","    model_name = get_working_model_name()\n","    print(f\"[System] Forced Safe Model: {model_name}\")\n","\n","    model = genai.GenerativeModel(model_name)\n","\n","    prompt = f\"\"\"\n","    Extract data from: \"{user_sentence}\"\n","    Return JSON with keys:\n","    1. \"stock_ticker\": The English ticker symbol (e.g. \"נוידיאה\" -> \"NVDA\").\n","    2. \"days\": Integer number of days.\n","    \"\"\"\n","\n","    for attempt in range(3):\n","        try:\n","            # We add a tiny delay to be safe\n","            time.sleep(1)\n","            response = model.generate_content(prompt)\n","            text = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n","            return json.loads(text)\n","        except Exception as e:\n","            if \"429\" in str(e):\n","                print(f\"[Warning] 429 Rate Limit. Waiting 5s...\")\n","                time.sleep(5)\n","            else:\n","                print(f\"[Error] {e}\")\n","                return None\n","    return None\n","\n","# --- Main Program ---\n","if __name__ == \"__main__\":\n","    print(\"--- Stock Prediction Setup (Lite Version) ---\")\n","    user_input = input(\"What would you like to predict and for how long: \")\n","\n","    result = extract_prediction_params(user_input)\n","\n","    if result:\n","        print(f\"\\n--- Success ---\")\n","        print(f\"Ticker: {result.get('stock_ticker')}\")\n","        print(f\"Days:   {result.get('days')}\")\n","    else:\n","        print(\"Failed to extract data.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"id":"bhMCZNe6qjQk","executionInfo":{"status":"ok","timestamp":1766602063503,"user_tz":-120,"elapsed":24666,"user":{"displayName":"Guy Ray","userId":"03709370811123485399"}},"outputId":"e30bd81a-a022-4e1c-dddd-9a41fa10fa13"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Stock Prediction Setup (Lite Version) ---\n","What would you like to predict and for how long: נוידיאה\n","[System] Forced Safe Model: models/gemini-2.0-flash-lite\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 535.32ms\n"]},{"output_type":"stream","name":"stdout","text":["[Warning] 429 Rate Limit. Waiting 5s...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 255.70ms\n"]},{"output_type":"stream","name":"stdout","text":["[Warning] 429 Rate Limit. Waiting 5s...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 255.48ms\n"]},{"output_type":"stream","name":"stdout","text":["[Warning] 429 Rate Limit. Waiting 5s...\n","Failed to extract data.\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJAMWboJDTgj/g35MSHgNP"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}