{"cells":[{"cell_type":"markdown","metadata":{"id":"4Ns2SNtAqGwM"},"source":["# Imports"]},{"cell_type":"code","source":["import sys\n","import os\n","import json\n","import warnings\n","import pickle\n","from dotenv import load_dotenv\n","\n","!pip install -U google-generativeai\n","import google.generativeai as genai\n","\n","from google.colab import drive\n","from google.colab import files\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","!pip install papermill\n","!pip install nbconvert\n","!pip install nbformat\n","!pip install IPython\n","\n","import papermill as pm\n","import nbformat\n","from nbconvert import HTMLExporter\n","from IPython.display import HTML, display\n","\n","warnings.filterwarnings(\"ignore\")\n","%matplotlib inline"],"metadata":{"id":"C_cNhJMevvae"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DRGyC6FrqbZA"},"source":["# Bootstrap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1d9o7FkEb0h"},"outputs":[],"source":["np.random.seed(31071967)\n","\n","load_dotenv()\n","\n","drive.mount('/content/drive')\n","\n","with open(f\"{os.getenv('PROJECT_PATH')}/src/config.json\", 'r') as f:\n","    project_config = json.load(f)\n","    project_config.pop('_comment', None)\n","    project_config.pop('_note', None)\n","    f.close()"]},{"cell_type":"code","source":["# Define our GOOGLE API KEY  in .env file. GOOGLE_API_KEY=<your api key>\n","genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"],"metadata":{"id":"SEXFQpYlC-uA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_best_available_model():\n","  \"\"\"\n","  Automatically finds a valid model name so we don't get 404 errors.\n","  Prefers 'flash' models (faster/cheaper), then 'pro'.\n","  \"\"\"\n","  print(\"[System] Scanning for available models...\")\n","  available_models = []\n","\n","  try:\n","      for m in genai.list_models():\n","          if 'generateContent' in m.supported_generation_methods:\n","              available_models.append(m.name)\n","\n","  except Exception as e:\n","      print(f\"Error listing models: {e}\")\n","      return None\n","\n","  # 1. Try to find a \"Flash\" model (Best for this task)\n","  for model_name in available_models:\n","    if \"flash\" in model_name and \"gemini\" in model_name:\n","      return model_name\n","\n","  # 2. If no Flash, look for a \"Pro\" model\n","  for model_name in available_models:\n","    if \"pro\" in model_name and \"gemini\" in model_name:\n","      return model_name\n","\n","  # 3. Fallback: just take the first \"gemini\" model found\n","  for model_name in available_models:\n","    if \"gemini\" in model_name:\n","      return model_name\n","\n","  return None"],"metadata":{"id":"Jrla57hEClRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_prediction_params(user_sentence):\n","    # 1. Dynamically get the model name\n","    model_name = get_best_available_model()\n","\n","    if not model_name:\n","        print(\"CRITICAL ERROR: No valid Gemini models found for your API key.\")\n","        return None\n","\n","    print(f\"[System] Using model: {model_name}\")\n","    model = genai.GenerativeModel(model_name)\n","\n","    prompt = f\"\"\"\n","    You are a data extraction assistant.\n","    Analyze this user request: \"{user_sentence}\"\n","\n","    Extract:\n","    1. \"stock_ticker\": The ticker symbol (e.g., \"Apple\" -> \"AAPL\").\n","    2. \"days\": The integer number of days for prediction (e.g., \"2 weeks\" -> 14).\n","\n","    Return ONLY raw JSON. Keys: 'stock_ticker', 'days'.\n","    \"\"\"\n","\n","    try:\n","        # Note: We removed 'response_mime_type' just in case your library version is old.\n","        # We will handle the JSON manually.\n","        response = model.generate_content(prompt)\n","\n","        # Clean up the text to ensure it's valid JSON (remove markdown backticks)\n","        clean_text = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n","        data = json.loads(clean_text)\n","        return data\n","\n","    except Exception as e:\n","        print(f\"Error extracting data: {e}\")\n","        return None"],"metadata":{"id":"1IbzNgnK8nMm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_target_tkl_from_user():\n","\n","  user_input = input(\"What would you like to predict and for how long: \") # e.g. \"Predict Google for 2 weeks\"\n","  result = extract_prediction_params(user_input)\n","\n","  while not result or result == None or result.get('stock_ticker') == None:\n","    print(\"\\nFailed to understand the proment. Please try again.\")\n","    user_input = input(\"\\nRequest: \")\n","    result = extract_prediction_params(user_input)\n","\n","  return result"],"metadata":{"id":"t7aE8viSI6Pl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def update_param_in_projet_config_file(param, new_value, file_path=f\"{os.getenv('PROJECT_PATH')}/src/config.json\"):\n","\n","    # 1. Check if file exists, if not, create a placeholder\n","    if not os.path.exists(file_path):\n","        print(f\"[Warning] {file_path} not found. Creating a new one.\")\n","        data = {}\n","    else:\n","        # 2. Read the existing data\n","        try:\n","            with open(file_path, 'r') as f:\n","                data = json.load(f)\n","        except json.JSONDecodeError:\n","            print(f\"[Error] {file_path} is empty or corrupted. Starting fresh.\")\n","            data = {}\n","\n","    # 3. Update the specific variable\n","    data[param] = new_value\n","\n","    # 4. Write everything back to the file\n","    with open(file_path, 'w') as f:\n","        json.dump(data, f, indent=4) # indent=4 makes it readable for humans\n","\n","    print(f\"Successfully updated {param} to: {new_value}\")"],"metadata":{"id":"fbv5VWfCKtb3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_notebook(notebook_name, output_name, parameters=None):\n","\n","  # --- Execute the proviuse notebook with parameters ---\n","  pm.execute_notebook(\n","      input_path = notebook_name,\n","      output_path = output_name,\n","      log_output=False,  # don't print logs while running\n","      progress_bar=True\n","  )\n","\n","  # --- Convert the executed notebook to HTML ---\n","  nb = nbformat.read(output_name, as_version=4)\n","  html_exporter = HTMLExporter()\n","  html_exporter.template_name = \"lab\"  # modern look; alternatives: 'classic', 'basic'\n","  body, _ = html_exporter.from_notebook_node(nb)\n","\n","  # --- Display the HTML result inline ---\n","  display(HTML(body))"],"metadata":{"id":"uNo88yYdOhIF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(user_selected_tkl, user_selected_days):\n","\n","  project_config['TKL'] = user_selected_tkl\n","  update_param_in_projet_config_file('TKL', user_selected_tkl)\n","  project_config['PRED.DAYS'] = user_selected_days\n","  update_param_in_projet_config_file('PRED.DAYS', user_selected_days)\n","\n","  input_file = f\"{os.getenv('PROJECT_PATH')}{project_config['notebooks_directory']}{project_config['notebook9']}\"\n","  output_file = f\"{os.getenv('PROJECT_PATH')}{project_config['output_directory']}{project_config['TKL']}.{project_config['output9']}\"\n","\n","  run_notebook(input_file, output_file)"],"metadata":{"id":"9S3J_FwvOh7E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.generativeai.client import configure\n","print(\"--- Stock Prediction Setup ---\")\n","\n","confirmed_user_params = False\n","while not confirmed_user_params:\n","\n","  result = get_target_tkl_from_user()\n","  days = int(result.get('days')) if result.get('days') != None else int(project_config[\"PRED.DAYS\"])\n","\n","  print(f\"Ticker: {result.get('stock_ticker')}\")\n","  print(f\"Days:   {days}\")\n","\n","  if days < 1 or days > 10:\n","    print(\"Days should be between 1 and 10\")\n","    continue\n","\n","  confirmed_user_params = (input(\"Pls confirm: [y=yes, n=no] \") == 'y')\n","\n","predict(result.get('stock_ticker'), days)"],"metadata":{"id":"BBvX8ay5JVjc"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsVZTbmjvNEjYLghBLWbFr"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}